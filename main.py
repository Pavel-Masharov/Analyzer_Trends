import asyncio
import pandas as pd

from configs.config import app_config
from src.data_collector.collector_manager import CollectorManager
from src.trend_analyzer.analyzer_manager import AnalyzerManager
from src.trend_analyzer.ml_analyzer import MLAnalyzer
from src.services.rag_manager import RAGManager


COLLECTION_HOURS = 240
MIN_CLUSTER_SIZE = 7


async def get_data() -> pd.DataFrame:
    """Getting data"""

    print("üì° –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
    collector_manager = CollectorManager(app_config)
    df = await collector_manager.collect_all_data(COLLECTION_HOURS)

    if not df.empty:
        print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df)} —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤")
        return df
    else:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        return None


async def run_data_analysis():
    """Data analysis"""

    print("üöÄ –ê–ù–ê–õ–ò–ó –†–ï–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–• + RAG")
    print("=" * 60)
    print(f"‚öôÔ∏è  –ù–ê–°–¢–†–û–ô–ö–ò:")
    print(f"   COLLECTION_HOURS: {COLLECTION_HOURS}")
    print(f"   MIN_CLUSTER_SIZE: {MIN_CLUSTER_SIZE}")
    print(f"\n1. üì° –ü–û–õ–£–ß–ï–ù–ò–ï –î–ê–ù–ù–´–•...")

    df = await get_data()

    if df.empty:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return

    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–ê–ù–ù–´–•:")
    print(f"   –í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤: {len(df)}")
    print(f"   –ü–ª–∞—Ç—Ñ–æ—Ä–º—ã: {df['platform'].value_counts().to_dict()}")
    print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {len(df['author'].unique())}")
    print(
        f"   –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç: {df['timestamp'].min().strftime('%Y-%m-%d %H:%M')} - {df['timestamp'].max().strftime('%Y-%m-%d %H:%M')}")
    print(
        f"   Engagement: {df['engagement_score'].min():.1f} - {df['engagement_score'].max():.1f} (avg: {df['engagement_score'].mean():.1f})")

    print(f"\n2. üîç –ê–ù–ê–õ–ò–ó –¢–†–ï–ù–î–û–í –° RAG...")

    rag_manager = RAGManager(app_config.rag_config)
    custom_analyzer = MLAnalyzer(
        min_cluster_size=MIN_CLUSTER_SIZE,
        rag_manager=rag_manager,
        use_external_knowledge=True
    )

    analyzer_manager = AnalyzerManager(rag_config=app_config.rag_config)
    analyzer_manager.analyzer = custom_analyzer

    trends = await analyzer_manager.find_trends(df)

    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(trends)} —Ç—Ä–µ–Ω–¥–æ–≤")
    print(f"\n3. üìà –î–ï–¢–ê–õ–¨–ù–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê –¢–†–ï–ù–î–û–í:")

    for i, trend in enumerate(trends, 1):
        print(f"\n{i}. üéØ {trend.theme}")
        print(f"   üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {trend.confidence:.1%}")
        print(f"   üìà –ü–æ—Å—Ç–æ–≤: {len(trend.posts)}")
        print(f"   üè∑Ô∏è  –ü–ª–∞—Ç—Ñ–æ—Ä–º—ã: {list(set(p.platform.value for p in trend.posts))}")
        print(f"   üìç –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {list(set(p.author for p in trend.posts[:3]))}")
        print(f"   üí° –û–±—â–∏–π Engagement: {sum(p.get_engagement_score() for p in trend.posts):.1f}")

        if trend.metadata.get("rag_enriched"):
            similar_trends = trend.metadata.get("similar_historical_trends", [])
            velocity = trend.metadata.get("trend_velocity", 1.0)
            context = trend.metadata.get("historical_context", "")

            print(f"   üéØ RAG –ê–ù–ê–õ–ò–¢–ò–ö–ê:")
            print(f"      ‚Ä¢ –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –∞–Ω–∞–ª–æ–≥–æ–≤: {len(similar_trends)}")
            print(f"      ‚Ä¢ –°–∫–æ—Ä–æ—Å—Ç—å —Ä–æ—Å—Ç–∞: {velocity:.1f}x")
            print(f"      ‚Ä¢ –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}")

            if similar_trends:
                print(f"      ‚Ä¢ –¢–æ–ø –∞–Ω–∞–ª–æ–≥–∏:")
                for similar in similar_trends[:2]:
                    confidence = similar.get('confidence', 0)
                    theme = similar.get('theme', 'Unknown')
                    print(f"        - {theme[:60]}... ({confidence:.1%})")

        print(f"   üî• –¢–æ–ø –ø–æ—Å—Ç—ã:")
        top_posts = sorted(trend.posts, key=lambda x: x.get_engagement_score(), reverse=True)[:2]
        for j, post in enumerate(top_posts, 1):
            short_text = post.text[:80] + "..." if len(post.text) > 80 else post.text
            print(f"      {j}. [{post.platform.value}] {post.author}: {short_text}")
            print(f"         Engagement: {post.get_engagement_score():.1f}")

    print(f"\n4. üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ò–°–¢–ï–ú–´:")
    print(f"   –í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤: {len(df)}")
    print(f"   –ù–∞–π–¥–µ–Ω–æ —Ç—Ä–µ–Ω–¥–æ–≤: {len(trends)}")
    rag_enriched = sum(1 for t in trends if t.metadata.get("rag_enriched"))
    print(f"   RAG –æ–±–æ–≥–∞—â–µ–Ω–æ: {rag_enriched}/{len(trends)}")

    if hasattr(custom_analyzer, 'last_clustering_quality'):
        print(f"   –ö–∞—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {custom_analyzer.last_clustering_quality:.3f}")

    if hasattr(custom_analyzer, 'last_analysis_stats'):
        stats = custom_analyzer.last_analysis_stats
        print(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {stats.get('avg_confidence', 0):.1%}")
        print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞: {stats.get('avg_cluster_size', 0):.1f}")


if __name__ == "__main__":
    asyncio.run(run_data_analysis())
